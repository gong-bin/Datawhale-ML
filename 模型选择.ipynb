{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#导入warnings包，利用过滤器来实现忽略警告语句。\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler() \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC,LinearRegression,LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 先导入之前处理好的数据\n",
    "train_path = '/Users/gongbin/Documents/数据竞赛/Datawhale/team-learning/数据竞赛（房租预测）/Data/train_data.csv'\n",
    "test_path = '/Users/gongbin/Documents/数据竞赛/Datawhale/team-learning/数据竞赛（房租预测）/Data/test_a.csv'\n",
    "data_train_origin = pd.read_csv(train_path)\n",
    "data_train = data_train_origin.copy()\n",
    "data_train['Type'] = 'Train'\n",
    "data_test_origin = pd.read_csv(test_path)\n",
    "data_test = data_test_origin.copy()\n",
    "data_test['Type'] = 'Test'\n",
    "data_all = pd.concat([data_train, data_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据进行处理\n",
    "def preprocessingData(data):\n",
    "    # 填充缺失值\n",
    "    data['rentType'][data['rentType'] == '--'] = '未知方式'  #进行填充\n",
    "    \n",
    "    # 转换object类型数据\n",
    "    columns = ['rentType','communityName','houseType', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate']\n",
    "    \n",
    "    for feature in columns:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "    # 将buildYear列转换为整型数据\n",
    "    buildYearmean = pd.DataFrame(data[data['buildYear'] != '暂无信息']['buildYear'].mode())  #用平均数填充\n",
    "    data.loc[data[data['buildYear'] == '暂无信息'].index, 'buildYear'] = buildYearmean.iloc[0, 0]\n",
    "    data['buildYear'] = data['buildYear'].astype('int')  #年份转成整数\n",
    "\n",
    "    # 处理pv和uv的空值\n",
    "    data['pv'].fillna(data['pv'].mean(), inplace=True)\n",
    "    data['uv'].fillna(data['uv'].mean(), inplace=True)\n",
    "    data['pv'] = data['pv'].astype('int')\n",
    "    data['uv'] = data['uv'].astype('int')\n",
    "\n",
    "    # 分割交易时间\n",
    "    def month(x):\n",
    "        month = int(x.split('/')[1])\n",
    "        return month\n",
    "    def year(x):\n",
    "        year = int(x.split('/')[0])\n",
    "        return year\n",
    "    data['month'] = data['tradeTime'].apply(lambda x: month(x))\n",
    "    data['year'] = data['tradeTime'].apply(lambda x: year(x))\n",
    "    \n",
    "    # 去掉部分特征\n",
    "    data.drop('city', axis=1, inplace=True)\n",
    "    data.drop('tradeTime', axis=1, inplace=True)\n",
    "    data.drop('ID', axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "data_train = preprocessingData(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([   62,    69,   128,   131,   246,   261,   266,   297,   308,\n",
      "              313,\n",
      "            ...\n",
      "            39224, 39228, 39319, 39347, 39352, 39434, 39563, 41080, 41083,\n",
      "            41233],\n",
      "           dtype='int64', length=403)\n"
     ]
    }
   ],
   "source": [
    "# clean data\n",
    "def IF_drop(train):\n",
    "    IForest = IsolationForest(contamination=0.01)\n",
    "    IForest.fit(train[\"tradeMoney\"].values.reshape(-1,1))\n",
    "    y_pred = IForest.predict(train[\"tradeMoney\"].values.reshape(-1,1))\n",
    "    drop_index = train.loc[y_pred==-1].index\n",
    "    print(drop_index)\n",
    "    train.drop(drop_index,inplace=True)\n",
    "    return train\n",
    "\n",
    "data_train = IF_drop(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropData(train):  \n",
    "    # 丢弃部分异常值\n",
    "    train = train[train.area <= 200]\n",
    "    train = train[(train.tradeMoney <=16000) & (train.tradeMoney >=700)]\n",
    "    train.drop(train[(train['totalFloor'] == 0)].index, inplace=True)\n",
    "    return train  \n",
    "#数据集异常值处理\n",
    "data_train = dropData(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newfeature(data):\n",
    "\n",
    "\n",
    "    # 将houseType转为'Room'，'Hall'，'Bath'    用于判断单个房间数量对结果的影响\n",
    "    '''\n",
    "    def Room(x):\n",
    "        Room = int(x.split('室')[0])\n",
    "        return Room\n",
    "    def Hall(x):\n",
    "        Hall = int(x.split(\"室\")[1].split(\"厅\")[0])\n",
    "        return Hall\n",
    "    def Bath(x):\n",
    "        Bath = int(x.split(\"室\")[1].split(\"厅\")[1].split(\"卫\")[0])\n",
    "        return Bath\n",
    "\n",
    "    data['Room'] = data['houseType'].apply(lambda x: Room(x))\n",
    "    data['Hall'] = data['houseType'].apply(lambda x: Hall(x))\n",
    "    data['Bath'] = data['houseType'].apply(lambda x: Bath(x))\n",
    "    data['Room_Bath'] = (data['Bath']+1) / (data['Room']+1)\n",
    "    # 填充租房类型    根据\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # data['day'] = data['tradeTime'].apply(lambda x: day(x))# 结果变差\n",
    "    #     data['pv/uv'] = data['pv'] / data['uv']\n",
    "    #     data['房间总数'] = data['室'] + data['厅'] + data['卫']\n",
    "\n",
    "    # 合并部分配套设施特征\n",
    "    data['trainsportNum'] = 5 * data['subwayStationNum'] / data['subwayStationNum'].mean() + data['busStationNum'] / \\\n",
    "                                                                                             data[\n",
    "                                                                                                 'busStationNum'].mean()\n",
    "    data['all_SchoolNum'] = 2 * data['interSchoolNum'] / data['interSchoolNum'].mean() + data['schoolNum'] / data[\n",
    "        'schoolNum'].mean() \\\n",
    "                            + data['privateSchoolNum'] / data['privateSchoolNum'].mean()\n",
    "    data['all_hospitalNum'] = 2 * data['hospitalNum'] / data['hospitalNum'].mean() + \\\n",
    "                              data['drugStoreNum'] / data['drugStoreNum'].mean()\n",
    "    data['all_mall'] = data['mallNum'] / data['mallNum'].mean() + \\\n",
    "                       data['superMarketNum'] / data['superMarketNum'].mean()\n",
    "    data['otherNum'] = data['gymNum'] / data['gymNum'].mean() + data['bankNum'] / data['bankNum'].mean() + \\\n",
    "                       data['shopNum'] / data['shopNum'].mean() + 2 * data['parkNum'] / data['parkNum'].mean()\n",
    "\n",
    "    data.drop(['subwayStationNum', 'busStationNum',\n",
    "               'interSchoolNum', 'schoolNum', 'privateSchoolNum',\n",
    "               'hospitalNum', 'drugStoreNum', 'mallNum', 'superMarketNum', 'gymNum', 'bankNum', 'shopNum', 'parkNum'],\n",
    "              axis=1, inplace=True)\n",
    "    # 提升0.0005\n",
    "    \n",
    "#     data['houseType_1sumcsu']=data['Bath'].map(lambda x:str(x))+data['month'].map(lambda x:str(x))\n",
    "#     data['houseType_2sumcsu']=data['Bath'].map(lambda x:str(x))+data['communityName']\n",
    "#     data['houseType_3sumcsu']=data['Bath'].map(lambda x:str(x))+data['plate']\n",
    "    \n",
    "    #data.drop('houseType', axis=1, inplace=True)\n",
    "    #data.drop('tradeTime', axis=1, inplace=True)\n",
    "    \n",
    "    data[\"area\"] = data[\"area\"].astype(int)\n",
    "\n",
    "\n",
    "    # categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName','region', 'plate']\n",
    "    categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate','cluster']\n",
    "\n",
    "    return data, categorical_feats\n",
    "data_train,categorical_feats = newfeature(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_back = data_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后续开始使用模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train_back.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入基础库\n",
    "from __future__ import print_function\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import numpy\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import colorama\n",
    "import numpy as np\n",
    "\n",
    "N_HYPEROPT_PROBES = 500\n",
    "HYPEROPT_ALGO = tpe.suggest  #  tpe.suggest OR hyperopt.rand.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorama.init()  #colorama可以让终端显示不同颜色\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def get_lgb_params(space):    #设置lgb的不同参数，在space的搜索框架内\n",
    "    lgb_params = dict()\n",
    "    lgb_params['boosting_type'] = space['boosting_type'] if 'boosting_type' in space else 'gbdt'\n",
    "    lgb_params['objective'] = 'regression'\n",
    "    lgb_params['metric'] = 'rmse'\n",
    "    lgb_params['learning_rate'] = space['learning_rate']\n",
    "    lgb_params['num_leaves'] = int(space['num_leaves'])\n",
    "    lgb_params['min_data_in_leaf'] = int(space['min_data_in_leaf'])\n",
    "    lgb_params['min_sum_hessian_in_leaf'] = space['min_sum_hessian_in_leaf']\n",
    "    lgb_params['max_depth'] = -1\n",
    "    lgb_params['lambda_l1'] = space['lambda_l1'] if 'lambda_l1' in space else 0.0\n",
    "    lgb_params['lambda_l2'] = space['lambda_l2'] if 'lambda_l2' in space else 0.0\n",
    "    lgb_params['max_bin'] = int(space['max_bin']) if 'max_bin' in space else 256\n",
    "    lgb_params['feature_fraction'] = space['feature_fraction']\n",
    "    lgb_params['bagging_fraction'] = space['bagging_fraction']\n",
    "    lgb_params['bagging_freq'] = int(space['bagging_freq']) if 'bagging_freq' in space else 1\n",
    "    lgb_params['nthread'] = 4\n",
    "    return lgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_call_count = 0\n",
    "cur_best_score = 0 # 0 or np.inf\n",
    "log_path = '/Users/gongbin/Documents/数据竞赛/Datawhale/team-learning/数据竞赛（房租预测）/Data/lgb-hyperopt-log.txt'\n",
    "log_writer = open(log_path, 'w' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>...</th>\n",
       "      <th>lookNum</th>\n",
       "      <th>tradeMoney</th>\n",
       "      <th>Type</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>trainsportNum</th>\n",
       "      <th>all_SchoolNum</th>\n",
       "      <th>all_hospitalNum</th>\n",
       "      <th>all_mall</th>\n",
       "      <th>otherNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.276900</td>\n",
       "      <td>0.737845</td>\n",
       "      <td>0.668611</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>2.249440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.716272</td>\n",
       "      <td>0.537449</td>\n",
       "      <td>0.926699</td>\n",
       "      <td>1.250894</td>\n",
       "      <td>2.534403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.535024</td>\n",
       "      <td>2.557029</td>\n",
       "      <td>1.799363</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>3.517453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.541916</td>\n",
       "      <td>4.099446</td>\n",
       "      <td>5.125212</td>\n",
       "      <td>1.727814</td>\n",
       "      <td>3.853332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1256</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.749075</td>\n",
       "      <td>0.310066</td>\n",
       "      <td>0.361324</td>\n",
       "      <td>0.727166</td>\n",
       "      <td>1.934998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  rentType  houseType  houseFloor  totalFloor  houseToward  \\\n",
       "0    68         2         12           1          16            6   \n",
       "1   125         2         28           0          14            6   \n",
       "2   132         2         28           1          32            6   \n",
       "3    57         2          4           0          17            6   \n",
       "4   129         2         29           1           2            6   \n",
       "\n",
       "   houseDecoration  communityName  region  plate  ...  lookNum  tradeMoney  \\\n",
       "0                0             50       0     63  ...        0      2000.0   \n",
       "1                2            129       1     48  ...        1      2000.0   \n",
       "2                0            178       1     49  ...        1     16000.0   \n",
       "3                3            312       1     50  ...        9      1600.0   \n",
       "4                1           1256       2     43  ...        0      2900.0   \n",
       "\n",
       "    Type  month  year  trainsportNum  all_SchoolNum  all_hospitalNum  \\\n",
       "0  Train     11  2018       6.276900       0.737845         0.668611   \n",
       "1  Train     12  2018       2.716272       0.537449         0.926699   \n",
       "2  Train     12  2018       5.535024       2.557029         1.799363   \n",
       "3  Train     12  2018       4.541916       4.099446         5.125212   \n",
       "4  Train     11  2018       0.749075       0.310066         0.361324   \n",
       "\n",
       "   all_mall  otherNum  \n",
       "0  0.743708  2.249440  \n",
       "1  1.250894  2.534403  \n",
       "2  0.999589  3.517453  \n",
       "3  1.727814  3.853332  \n",
       "4  0.727166  1.934998  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = data_train.pop('tradeMoney')\n",
    "X_train = data_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Train\n",
       "1        Train\n",
       "2        Train\n",
       "3        Train\n",
       "4        Train\n",
       "         ...  \n",
       "41435    Train\n",
       "41436    Train\n",
       "41437    Train\n",
       "41438    Train\n",
       "41439    Train\n",
       "Name: Type, Length: 40215, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.pop('Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-51fd5fde59c6>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-51fd5fde59c6>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    golbal X_train, Y_train\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def objective(space):\n",
    "    global obj_call_count, cur_best_score\n",
    "    golbal X_train, Y_train\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nLightGBM objective call #{} cur_best_score={:7.5f}'.format(obj_call_count,cur_best_score) )\n",
    "\n",
    "    lgb_params = get_lgb_params(space)  #获得参数列表\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "    \n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    out_of_fold = np.zeros(len(X_train))\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        D_train = lgb.Dataset(X_train.iloc[train_idx], label=Y_train[train_idx])\n",
    "        D_val = lgb.Dataset(X_train.iloc[val_idx], label=Y_train[val_idx])\n",
    "        # Train\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(lgb_params,\n",
    "                           D_train,\n",
    "                           num_boost_round=num_round,\n",
    "                           # metrics='mlogloss',\n",
    "                           valid_sets=D_val,\n",
    "                           # valid_names='val',\n",
    "                           # fobj=None,\n",
    "                           # feval=None,\n",
    "                           # init_model=None,\n",
    "                           # feature_name='auto',\n",
    "                           # categorical_feature='auto',\n",
    "                           early_stopping_rounds=200,\n",
    "                           # evals_result=None,\n",
    "                           verbose_eval=False,\n",
    "                           # learning_rates=None,\n",
    "                           # keep_training_booster=False,\n",
    "                           # callbacks=None\n",
    "                           )\n",
    "        # predict\n",
    "        nb_trees = clf.best_iteration\n",
    "        val_loss = clf.best_score['valid_0']\n",
    "        print('nb_trees={} val_loss={}'.format(nb_trees, val_loss))\n",
    "        out_of_fold[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=nb_trees)\n",
    "        score = r2_score(out_of_fold, Y_train)\n",
    "\n",
    "    print('val_r2_score={}'.format(score))\n",
    "\n",
    "    log_writer.write('score={} Params:{} nb_trees={}\\n'.format(score, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if score>cur_best_score:\n",
    "        cur_best_score = score\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST SCORE={}'.format(cur_best_score) + colorama.Fore.RESET)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "LightGBM objective call #3 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7600202470526277 bagging_freq=1.0 feature_fraction=0.8603765313417686 lambda_l1=4.336712854330386 lambda_l2=6.578510252633993 learning_rate=0.00785100974426483 max_bin=178.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=1.9256322894467406 num_leaves=87.0\n",
      "nb_trees=256 val_loss=OrderedDict([('rmse', 2511.4287657658656)])\n",
      "nb_trees=217 val_loss=OrderedDict([('rmse', 2556.392157761859)])\n",
      "nb_trees=222 val_loss=OrderedDict([('rmse', 2578.9320844564654)])\n",
      "val_r2_score=-54.21933911397814                        \n",
      "                                                                                  \n",
      "LightGBM objective call #4 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7949270954837502 bagging_freq=12.0 feature_fraction=0.9794080784197502 lambda_l1=2.7361697517290064 lambda_l2=2.081264315598502 learning_rate=0.004589984719741015 max_bin=89.0 min_data_in_leaf=46.0 min_sum_hessian_in_leaf=1.3992147347244115 num_leaves=54.0\n",
      "nb_trees=452 val_loss=OrderedDict([('rmse', 2511.87811041394)])                   \n",
      "nb_trees=515 val_loss=OrderedDict([('rmse', 2555.8658790280256)])                 \n",
      "nb_trees=414 val_loss=OrderedDict([('rmse', 2578.5177417154205)])                 \n",
      "val_r2_score=-55.45307052399088                                                   \n",
      "                                                                                  \n",
      "LightGBM objective call #5 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8249916374952474 bagging_freq=12.0 feature_fraction=0.8666733305388981 lambda_l1=6.9619031050238025 lambda_l2=5.359302135742599 learning_rate=0.00304249734013475 max_bin=102.0 min_data_in_leaf=21.0 min_sum_hessian_in_leaf=1.1422231598203079 num_leaves=84.0\n",
      "nb_trees=647 val_loss=OrderedDict([('rmse', 2511.5203680056916)])                 \n",
      "nb_trees=577 val_loss=OrderedDict([('rmse', 2555.8737763454096)])                 \n",
      "nb_trees=544 val_loss=OrderedDict([('rmse', 2578.890432531505)])                  \n",
      "val_r2_score=-55.79233334575989                                                   \n",
      "                                                                                  \n",
      "LightGBM objective call #6 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8382328792805184 bagging_freq=3.0 feature_fraction=0.7543315429833364 lambda_l1=7.638990453598162 lambda_l2=8.539381222977427 learning_rate=0.004669596787260302 max_bin=132.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=4.877284366275228 num_leaves=98.0\n",
      "nb_trees=464 val_loss=OrderedDict([('rmse', 2510.4077549297535)])                 \n",
      "nb_trees=397 val_loss=OrderedDict([('rmse', 2556.440861353371)])                  \n",
      "nb_trees=387 val_loss=OrderedDict([('rmse', 2579.7783992333643)])                 \n",
      "val_r2_score=-48.44957657032757                                                   \n",
      "                                                                                  \n",
      "LightGBM objective call #7 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8637901817852895 bagging_freq=13.0 feature_fraction=0.7998020112473121 lambda_l1=0.15914511232760664 lambda_l2=3.119952583323695 learning_rate=0.007728918837797189 max_bin=95.0 min_data_in_leaf=44.0 min_sum_hessian_in_leaf=8.360771392309575 num_leaves=73.0\n",
      "nb_trees=332 val_loss=OrderedDict([('rmse', 2510.9915783736187)])                 \n",
      "nb_trees=243 val_loss=OrderedDict([('rmse', 2555.957042237307)])                  \n",
      "nb_trees=238 val_loss=OrderedDict([('rmse', 2578.498826869128)])                  \n",
      "val_r2_score=-49.966157187823                                                     \n",
      "                                                                                  \n",
      "LightGBM objective call #8 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7520804917156068 bagging_freq=10.0 feature_fraction=0.9163673323915584 lambda_l1=6.462383832611469 lambda_l2=7.209896470752946 learning_rate=0.005633920318336276 max_bin=101.0 min_data_in_leaf=50.0 min_sum_hessian_in_leaf=1.0821220799261058 num_leaves=20.0\n",
      "nb_trees=802 val_loss=OrderedDict([('rmse', 2511.4095226335116)])                 \n",
      "nb_trees=582 val_loss=OrderedDict([('rmse', 2557.786011229233)])                  \n",
      "nb_trees=640 val_loss=OrderedDict([('rmse', 2580.491416698908)])                  \n",
      "val_r2_score=-63.94712441600964                                                   \n",
      "                                                                                  \n",
      "LightGBM objective call #9 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7795179252366474 bagging_freq=6.0 feature_fraction=0.7929125624752046 lambda_l1=5.8163869185417045 lambda_l2=4.872304862088926 learning_rate=0.008065058059255675 max_bin=93.0 min_data_in_leaf=44.0 min_sum_hessian_in_leaf=2.36975177612423 num_leaves=55.0\n",
      "nb_trees=359 val_loss=OrderedDict([('rmse', 2510.330271227196)])                \n",
      "nb_trees=282 val_loss=OrderedDict([('rmse', 2555.421209304911)])                \n",
      "nb_trees=285 val_loss=OrderedDict([('rmse', 2578.9966598159513)])               \n",
      "val_r2_score=-50.444514603583194                                                \n",
      "                                                                                \n",
      "LightGBM objective call #10 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9617548011979901 bagging_freq=11.0 feature_fraction=0.9721773745411372 lambda_l1=5.963239442298274 lambda_l2=7.611355061640552 learning_rate=0.003783392544994798 max_bin=126.0 min_data_in_leaf=42.0 min_sum_hessian_in_leaf=9.885462685425727 num_leaves=67.0\n",
      "nb_trees=649 val_loss=OrderedDict([('rmse', 2511.323582230028)])                \n",
      "nb_trees=435 val_loss=OrderedDict([('rmse', 2556.2793858954383)])               \n",
      "nb_trees=461 val_loss=OrderedDict([('rmse', 2577.156358993037)])                \n",
      "val_r2_score=-52.905144352552                                                   \n",
      "                                                                                  \n",
      "LightGBM objective call #11 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9375239102278177 bagging_freq=9.0 feature_fraction=0.7887426668811344 lambda_l1=1.2658160204301239 lambda_l2=4.0729069415729064 learning_rate=0.00830804753415933 max_bin=154.0 min_data_in_leaf=74.0 min_sum_hessian_in_leaf=4.090410451354006 num_leaves=25.0\n",
      "nb_trees=532 val_loss=OrderedDict([('rmse', 2511.015040786437)])                  \n",
      "nb_trees=412 val_loss=OrderedDict([('rmse', 2555.7780673522143)])                 \n",
      "nb_trees=450 val_loss=OrderedDict([('rmse', 2578.5197238820865)])                 \n",
      "val_r2_score=-54.25463937032936                                                   \n",
      "                                                                                  \n",
      "LightGBM objective call #12 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.947182323432054 bagging_freq=3.0 feature_fraction=0.8089489158660474 lambda_l1=0.9576343323247649 lambda_l2=8.920658913023257 learning_rate=0.005935367722171546 max_bin=189.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=5.347094067418845 num_leaves=40.0\n",
      "nb_trees=627 val_loss=OrderedDict([('rmse', 2511.477255994373)])                \n",
      "nb_trees=409 val_loss=OrderedDict([('rmse', 2554.663675671228)])                \n",
      "nb_trees=459 val_loss=OrderedDict([('rmse', 2577.32524750213)])                 \n",
      "val_r2_score=-55.66503439937373                                                 \n",
      "                                                                                   \n",
      "LightGBM objective call #13 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9880173074934014 bagging_freq=1.0 feature_fraction=0.8801719270830747 lambda_l1=1.2792653705039858 lambda_l2=6.983833264293499 learning_rate=0.0050703521395454336 max_bin=134.0 min_data_in_leaf=86.0 min_sum_hessian_in_leaf=1.0624074082583048 num_leaves=38.0\n",
      "nb_trees=652 val_loss=OrderedDict([('rmse', 2509.8862919867497)])                  \n",
      "nb_trees=460 val_loss=OrderedDict([('rmse', 2555.805685174249)])                   \n",
      "nb_trees=487 val_loss=OrderedDict([('rmse', 2578.0141176432207)])                  \n",
      "val_r2_score=-53.3882348286384                                                     \n",
      "                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM objective call #14 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9151201715146451 bagging_freq=11.0 feature_fraction=0.7745356284772779 lambda_l1=2.8060605320855947 lambda_l2=7.852083246963203 learning_rate=0.0006838591653925997 max_bin=136.0 min_data_in_leaf=49.0 min_sum_hessian_in_leaf=1.6466244906572336 num_leaves=18.0\n",
      "nb_trees=7397 val_loss=OrderedDict([('rmse', 2511.776730947409)])                  \n",
      "nb_trees=5743 val_loss=OrderedDict([('rmse', 2555.9992449127017)])                 \n",
      "nb_trees=6201 val_loss=OrderedDict([('rmse', 2579.4215717657758)])                 \n",
      "val_r2_score=-62.99097365909645                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #15 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9143155860180489 bagging_freq=15.0 feature_fraction=0.8549404898534534 lambda_l1=6.094738252790846 lambda_l2=5.4260924849244185 learning_rate=0.004143550425292757 max_bin=105.0 min_data_in_leaf=17.0 min_sum_hessian_in_leaf=3.6311889765876404 num_leaves=39.0\n",
      "nb_trees=735 val_loss=OrderedDict([('rmse', 2511.512794443581)])                   \n",
      "nb_trees=659 val_loss=OrderedDict([('rmse', 2554.9828168424997)])                  \n",
      "nb_trees=623 val_loss=OrderedDict([('rmse', 2577.244701603937)])                   \n",
      "val_r2_score=-57.14667703041954                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #16 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9824634003067392 bagging_freq=4.0 feature_fraction=0.8171467833834598 lambda_l1=7.857333890935695 lambda_l2=6.565922480461621 learning_rate=0.007397695901676385 max_bin=166.0 min_data_in_leaf=16.0 min_sum_hessian_in_leaf=8.467088130508497 num_leaves=35.0\n",
      "nb_trees=556 val_loss=OrderedDict([('rmse', 2511.2150418781375)])                  \n",
      "nb_trees=306 val_loss=OrderedDict([('rmse', 2554.446375876273)])                   \n",
      "nb_trees=392 val_loss=OrderedDict([('rmse', 2577.1018487806396)])                  \n",
      "val_r2_score=-57.52125404359301                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #17 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.856909890154026 bagging_freq=10.0 feature_fraction=0.8077076089406023 lambda_l1=7.013906608594782 lambda_l2=0.3943649638493196 learning_rate=0.007421358099518003 max_bin=120.0 min_data_in_leaf=57.0 min_sum_hessian_in_leaf=1.0486592309847278 num_leaves=94.0\n",
      "nb_trees=226 val_loss=OrderedDict([('rmse', 2512.1909340743505)])                  \n",
      "nb_trees=229 val_loss=OrderedDict([('rmse', 2556.801680114846)])                   \n",
      "nb_trees=290 val_loss=OrderedDict([('rmse', 2579.658147513157)])                   \n",
      "val_r2_score=-48.19240094928709                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #18 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9215415682096995 bagging_freq=9.0 feature_fraction=0.8050715826339728 lambda_l1=0.6462178379529382 lambda_l2=1.0068000202714078 learning_rate=0.0003395408474000938 max_bin=109.0 min_data_in_leaf=97.0 min_sum_hessian_in_leaf=8.657568450477749 num_leaves=52.0\n",
      "nb_trees=7245 val_loss=OrderedDict([('rmse', 2508.6387583659794)])                 \n",
      "nb_trees=6400 val_loss=OrderedDict([('rmse', 2555.128181152959)])                  \n",
      "nb_trees=6111 val_loss=OrderedDict([('rmse', 2577.991491038494)])                  \n",
      "val_r2_score=-53.21320941469322                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #19 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9256549926172393 bagging_freq=6.0 feature_fraction=0.9595691843496377 lambda_l1=7.902632484609456 lambda_l2=1.1232930394037388 learning_rate=0.00801712628777691 max_bin=198.0 min_data_in_leaf=80.0 min_sum_hessian_in_leaf=2.671838003822352 num_leaves=31.0\n",
      "nb_trees=503 val_loss=OrderedDict([('rmse', 2510.37144032856)])                    \n",
      "nb_trees=300 val_loss=OrderedDict([('rmse', 2555.53432516505)])                    \n",
      "nb_trees=420 val_loss=OrderedDict([('rmse', 2578.867169500247)])                   \n",
      "val_r2_score=-53.21398651606845                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #20 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9572626636129272 bagging_freq=10.0 feature_fraction=0.8299292405143573 lambda_l1=4.64703360169368 lambda_l2=4.050079482063557 learning_rate=0.0063987023762825225 max_bin=132.0 min_data_in_leaf=82.0 min_sum_hessian_in_leaf=1.5557661115609214 num_leaves=58.0\n",
      "nb_trees=330 val_loss=OrderedDict([('rmse', 2510.077613071539)])                   \n",
      "nb_trees=300 val_loss=OrderedDict([('rmse', 2555.2798064758567)])                  \n",
      "nb_trees=350 val_loss=OrderedDict([('rmse', 2578.2307484559324)])                  \n",
      "val_r2_score=-52.23030234760632                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #21 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8084836720879888 bagging_freq=2.0 feature_fraction=0.8667619944515677 lambda_l1=4.698609359344164 lambda_l2=5.637401478879896 learning_rate=0.0026623545550644146 max_bin=138.0 min_data_in_leaf=14.0 min_sum_hessian_in_leaf=4.890386854805828 num_leaves=25.0\n",
      "nb_trees=1500 val_loss=OrderedDict([('rmse', 2512.075936402061)])                  \n",
      "nb_trees=1224 val_loss=OrderedDict([('rmse', 2556.148963284372)])                  \n",
      "nb_trees=1242 val_loss=OrderedDict([('rmse', 2579.2615060525045)])                 \n",
      "val_r2_score=-64.19346675571421                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #22 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.7711271222596882 bagging_freq=2.0 feature_fraction=0.7840636135965674 lambda_l1=2.657977055602707 lambda_l2=0.6511741527857173 learning_rate=0.004770541669489988 max_bin=145.0 min_data_in_leaf=15.0 min_sum_hessian_in_leaf=9.726088132401149 num_leaves=50.0\n",
      "nb_trees=625 val_loss=OrderedDict([('rmse', 2511.7241758385726)])                  \n",
      "nb_trees=497 val_loss=OrderedDict([('rmse', 2555.7157090397686)])                  \n",
      "nb_trees=506 val_loss=OrderedDict([('rmse', 2578.6179379945092)])                  \n",
      "val_r2_score=-55.445540475195614                                                   \n",
      "                                                                                   \n",
      "LightGBM objective call #23 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8563009505265741 bagging_freq=7.0 feature_fraction=0.7538473721035468 lambda_l1=9.63810761110119 lambda_l2=9.320833553897138 learning_rate=0.009115493012809749 max_bin=119.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=6.166222468509104 num_leaves=99.0\n",
      "nb_trees=229 val_loss=OrderedDict([('rmse', 2510.641110284978)])                   \n",
      "nb_trees=147 val_loss=OrderedDict([('rmse', 2556.71646866518)])                    \n",
      "nb_trees=210 val_loss=OrderedDict([('rmse', 2579.012764301711)])                   \n",
      "val_r2_score=-51.147285720497756                                                   \n",
      "                                                                                   \n",
      "LightGBM objective call #24 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8844366289512233 bagging_freq=15.0 feature_fraction=0.7542993345717716 lambda_l1=9.49868456704908 lambda_l2=8.507923063387596 learning_rate=0.001620204085511041 max_bin=117.0 min_data_in_leaf=62.0 min_sum_hessian_in_leaf=2.949161793207662 num_leaves=98.0\n",
      "nb_trees=1278 val_loss=OrderedDict([('rmse', 2510.796656825186)])                  \n",
      "nb_trees=1185 val_loss=OrderedDict([('rmse', 2555.687370591692)])                  \n",
      "nb_trees=1080 val_loss=OrderedDict([('rmse', 2578.5359877573924)])                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_r2_score=-48.06808131378857                                                    \n",
      "                                                                                   \n",
      "LightGBM objective call #25 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8926498968598582 bagging_freq=15.0 feature_fraction=0.7515556194566675 lambda_l1=9.795163123774673 lambda_l2=2.355519334275221 learning_rate=0.0018561305928347662 max_bin=113.0 min_data_in_leaf=62.0 min_sum_hessian_in_leaf=2.8576592022234424 num_leaves=88.0\n",
      "nb_trees=1066 val_loss=OrderedDict([('rmse', 2510.7035012776378)])                 \n",
      "nb_trees=1185 val_loss=OrderedDict([('rmse', 2555.7627364635787)])                 \n",
      "nb_trees=1057 val_loss=OrderedDict([('rmse', 2578.1744237478138)])                 \n",
      "val_r2_score=-46.084346636055365                                                   \n",
      "                                                                                    \n",
      "LightGBM objective call #26 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8817019868033179 bagging_freq=15.0 feature_fraction=0.7619086776319254 lambda_l1=9.533201246276795 lambda_l2=9.932842503866745 learning_rate=0.001528963000561068 max_bin=113.0 min_data_in_leaf=68.0 min_sum_hessian_in_leaf=3.2385989007135576 num_leaves=80.0\n",
      "nb_trees=1349 val_loss=OrderedDict([('rmse', 2510.1113908714815)])                  \n",
      "nb_trees=1349 val_loss=OrderedDict([('rmse', 2555.256056965878)])                   \n",
      "nb_trees=1249 val_loss=OrderedDict([('rmse', 2577.8456214370963)])                  \n",
      "val_r2_score=-49.81492543231043                                                     \n",
      "                                                                                    \n",
      "LightGBM objective call #27 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8899580497626692 bagging_freq=14.0 feature_fraction=0.8382569958610789 lambda_l1=8.90530627920422 lambda_l2=2.099219319392156 learning_rate=0.001549311781774822 max_bin=148.0 min_data_in_leaf=93.0 min_sum_hessian_in_leaf=2.512585257050712 num_leaves=91.0\n",
      "nb_trees=1273 val_loss=OrderedDict([('rmse', 2509.8932639972436)])                  \n",
      "nb_trees=1084 val_loss=OrderedDict([('rmse', 2556.581092459826)])                   \n",
      "nb_trees=1226 val_loss=OrderedDict([('rmse', 2579.2436859225795)])                  \n",
      "val_r2_score=-48.662898783194116                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #28 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8868715057569458 bagging_freq=14.0 feature_fraction=0.8991618339683811 lambda_l1=8.700312891304982 lambda_l2=2.42274912085284 learning_rate=0.0017734259628850975 max_bin=116.0 min_data_in_leaf=29.0 min_sum_hessian_in_leaf=2.0549350707023737 num_leaves=76.0\n",
      "nb_trees=1179 val_loss=OrderedDict([('rmse', 2510.751412760535)])                   \n",
      "nb_trees=945 val_loss=OrderedDict([('rmse', 2555.901421800509)])                    \n",
      "nb_trees=1032 val_loss=OrderedDict([('rmse', 2578.686275402513)])                   \n",
      "val_r2_score=-53.93038345490986                                                     \n",
      "                                                                                    \n",
      "LightGBM objective call #29 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9007165792601631 bagging_freq=14.0 feature_fraction=0.9414315870752211 lambda_l1=9.955659862612828 lambda_l2=3.653568488797892 learning_rate=0.0026133132948025885 max_bin=158.0 min_data_in_leaf=65.0 min_sum_hessian_in_leaf=2.9562555331493243 num_leaves=67.0\n",
      "nb_trees=923 val_loss=OrderedDict([('rmse', 2510.826777822731)])                    \n",
      "nb_trees=713 val_loss=OrderedDict([('rmse', 2555.6260136740543)])                   \n",
      "nb_trees=574 val_loss=OrderedDict([('rmse', 2578.8701438398075)])                   \n",
      "val_r2_score=-53.586692955643045                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #30 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8376171879422825 bagging_freq=13.0 feature_fraction=0.9972793356959779 lambda_l1=8.818782185640904 lambda_l2=2.7487440500429434 learning_rate=0.0008209576420463575 max_bin=125.0 min_data_in_leaf=72.0 min_sum_hessian_in_leaf=3.6732812476953174 num_leaves=99.0\n",
      "nb_trees=2054 val_loss=OrderedDict([('rmse', 2511.467564824507)])                   \n",
      "nb_trees=1950 val_loss=OrderedDict([('rmse', 2556.9810285752637)])                  \n",
      "nb_trees=2041 val_loss=OrderedDict([('rmse', 2578.7891027484725)])                  \n",
      "val_r2_score=-51.798513411429454                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #31 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8996029975737863 bagging_freq=15.0 feature_fraction=0.7741253861479722 lambda_l1=3.622110205079232 lambda_l2=6.10027653062008 learning_rate=6.629411092066734e-05 max_bin=167.0 min_data_in_leaf=32.0 min_sum_hessian_in_leaf=1.9712126639881538 num_leaves=88.0\n",
      "nb_trees=10000 val_loss=OrderedDict([('rmse', 2518.927214449405)])                  \n",
      "nb_trees=10000 val_loss=OrderedDict([('rmse', 2561.987716251458)])                  \n",
      "nb_trees=10000 val_loss=OrderedDict([('rmse', 2584.7560634341557)])                 \n",
      "val_r2_score=-182.28866343199417                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #32 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8421054702519116 bagging_freq=13.0 feature_fraction=0.7504920990648162 lambda_l1=9.18119629808449 lambda_l2=1.6061754208281072 learning_rate=0.0032777239897968853 max_bin=97.0 min_data_in_leaf=59.0 min_sum_hessian_in_leaf=6.221105574332238 num_leaves=84.0\n",
      "nb_trees=659 val_loss=OrderedDict([('rmse', 2510.324792139609)])                    \n",
      "nb_trees=507 val_loss=OrderedDict([('rmse', 2556.3457219191037)])                   \n",
      "nb_trees=525 val_loss=OrderedDict([('rmse', 2578.379272117617)])                    \n",
      "val_r2_score=-52.655084758111634                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #33 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8142900143625006 bagging_freq=12.0 feature_fraction=0.8423403954651942 lambda_l1=9.983135963266628 lambda_l2=4.660761069124192 learning_rate=0.002126760916222213 max_bin=88.0 min_data_in_leaf=38.0 min_sum_hessian_in_leaf=2.3057473952219825 num_leaves=64.0\n",
      "nb_trees=1093 val_loss=OrderedDict([('rmse', 2510.425088844719)])                   \n",
      "nb_trees=947 val_loss=OrderedDict([('rmse', 2554.8661179426304)])                   \n",
      "nb_trees=947 val_loss=OrderedDict([('rmse', 2578.3782756144765)])                   \n",
      "val_r2_score=-53.74739534676317                                                     \n",
      "                                                                                    \n",
      "LightGBM objective call #34 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8713889641030403 bagging_freq=8.0 feature_fraction=0.7687161635611782 lambda_l1=8.4196942933035 lambda_l2=3.1518227270815693 learning_rate=0.003641505302739945 max_bin=110.0 min_data_in_leaf=76.0 min_sum_hessian_in_leaf=1.273607730208044 num_leaves=94.0\n",
      "nb_trees=529 val_loss=OrderedDict([('rmse', 2510.8195719941145)])                   \n",
      "nb_trees=442 val_loss=OrderedDict([('rmse', 2556.000213790844)])                    \n",
      "nb_trees=527 val_loss=OrderedDict([('rmse', 2578.726455523967)])                    \n",
      "val_r2_score=-49.86486115756782                                                     \n",
      "                                                                                    \n",
      "LightGBM objective call #35 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9987850239613182 bagging_freq=14.0 feature_fraction=0.8234673693069878 lambda_l1=7.11042424864497 lambda_l2=0.006605105499362551 learning_rate=0.0010949225489331501 max_bin=125.0 min_data_in_leaf=86.0 min_sum_hessian_in_leaf=2.9858572890693647 num_leaves=75.0\n",
      "nb_trees=1849 val_loss=OrderedDict([('rmse', 2510.192041291942)])                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=1832 val_loss=OrderedDict([('rmse', 2555.775689148702)])                   \n",
      "nb_trees=1692 val_loss=OrderedDict([('rmse', 2578.602945586642)])                   \n",
      "val_r2_score=-48.226554204838266                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #36 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.791030850955777 bagging_freq=12.0 feature_fraction=0.8975401949006084 lambda_l1=5.1758865987256355 lambda_l2=9.824950126108586 learning_rate=0.0023232513893085517 max_bin=103.0 min_data_in_leaf=25.0 min_sum_hessian_in_leaf=1.7490463954234527 num_leaves=11.0\n",
      "nb_trees=3419 val_loss=OrderedDict([('rmse', 2513.4900415477377)])                  \n",
      "nb_trees=2784 val_loss=OrderedDict([('rmse', 2557.469003460902)])                   \n",
      "nb_trees=2988 val_loss=OrderedDict([('rmse', 2581.407969168624)])                   \n",
      "val_r2_score=-63.465356572425335                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #37 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.9045692890872067 bagging_freq=12.0 feature_fraction=0.7507014833992954 lambda_l1=8.014808450592698 lambda_l2=1.8356021095034405 learning_rate=0.002966668173668863 max_bin=141.0 min_data_in_leaf=51.0 min_sum_hessian_in_leaf=3.650634465705039 num_leaves=82.0\n",
      "nb_trees=746 val_loss=OrderedDict([('rmse', 2510.348940508364)])                    \n",
      "nb_trees=669 val_loss=OrderedDict([('rmse', 2555.6990545591625)])                   \n",
      "nb_trees=637 val_loss=OrderedDict([('rmse', 2578.968974290114)])                    \n",
      "val_r2_score=-48.957932968148455                                                    \n",
      "                                                                                    \n",
      "LightGBM objective call #38 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8714555789973087 bagging_freq=5.0 feature_fraction=0.932445334226764 lambda_l1=5.373002520281126 lambda_l2=8.379456832607211 learning_rate=0.0011490282619102386 max_bin=90.0 min_data_in_leaf=61.0 min_sum_hessian_in_leaf=2.0786690300288577 num_leaves=88.0\n",
      "nb_trees=1834 val_loss=OrderedDict([('rmse', 2510.580848053015)])                   \n",
      "nb_trees=1540 val_loss=OrderedDict([('rmse', 2555.171754045154)])                   \n",
      "nb_trees=1604 val_loss=OrderedDict([('rmse', 2578.463271499779)])                   \n",
      "val_r2_score=-49.19141322819217                                                     \n",
      "                                                                                    \n",
      "LightGBM objective call #39 cur_best_score=0.00000\n",
      "Params: bagging_fraction=0.8390027772306989 bagging_freq=11.0 feature_fraction=0.7832393407259013 lambda_l1=6.6341146423588375 lambda_l2=4.54678600848708 learning_rate=1.63453207475241e-05 max_bin=98.0 min_data_in_leaf=54.0 min_sum_hessian_in_leaf=4.167618213701111 num_leaves=47.0\n",
      "  7%|▋         | 36/500 [12:16<2:38:08, 20.45s/trial, best loss: 46.084346636055365]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b3be65229ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                      \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_HYPEROPT_PROBES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                      \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                      verbose=1)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             )\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6fafbe190ff0>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m     32\u001b[0m                            \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                            \u001b[0;31m# evals_result=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                            \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                            \u001b[0;31m# learning_rates=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                            \u001b[0;31m# keep_training_booster=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space ={\n",
    "        'num_leaves': hp.quniform ('num_leaves', 10, 100, 1),\n",
    "        'min_data_in_leaf':  hp.quniform ('min_data_in_leaf', 10, 100, 1),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.75, 1.0),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.75, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0, 0.01),\n",
    "#         'learning_rate': hp.loguniform('learning_rate', -5.0, -2.3),\n",
    "        'min_sum_hessian_in_leaf': hp.loguniform('min_sum_hessian_in_leaf', 0, 2.3),\n",
    "        'max_bin': hp.quniform ('max_bin', 88, 200, 1),\n",
    "        'bagging_freq': hp.quniform ('bagging_freq', 1, 15, 1),\n",
    "        'lambda_l1': hp.uniform('lambda_l1', 0, 10 ),\n",
    "        'lambda_l2': hp.uniform('lambda_l2', 0, 10 ),\n",
    "       }\n",
    "\n",
    "trials = Trials()\n",
    "best = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=1)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
