{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler() \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC,LinearRegression,LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/Users/gongbin/Documents/数据竞赛/Datawhale/team-learning/数据竞赛（房租预测）/Data/train_data_clean.csv'\n",
    "test_path = '/Users/gongbin/Documents/数据竞赛/Datawhale/team-learning/数据竞赛（房租预测）/Data/test_a_clean.csv'\n",
    "test_y_path = '/Users/gongbin/Documents/数据竞赛/Datawhale/team-learning/数据竞赛（房租预测）/Data/评分文件/sub_a_913.csv'\n",
    "train_X = pd.read_csv(train_path)\n",
    "test_X = pd.read_csv(test_path)\n",
    "train_X.pop('Type')\n",
    "test_X.pop('Type')\n",
    "train_X.pop('Unnamed: 0')\n",
    "test_X.pop('Unnamed: 0')\n",
    "test_Y = pd.read_csv(test_y_path)\n",
    "train_Y = train_X.pop('tradeMoney')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.使用RandomForestRegressor训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8698089  0.86056329 0.86161657 0.86850468 0.87583451]\n",
      "0.8672655891715111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "randomForest_model = RandomForestRegressor()\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "score_ndarray = cross_val_score(randomForest_model, train_X, train_Y, cv=kf)\n",
    "print(score_ndarray)\n",
    "print(score_ndarray.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max score: 0.8931630753825089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "sample_leaf_options = [10,50,100,200,500]\n",
    "\n",
    "max_score = 0\n",
    "for leaf_size in sample_leaf_options:\n",
    "    model = RandomForestRegressor(n_estimators = 200, n_jobs = -1,random_state =50,\n",
    "                                  max_features = \"auto\", min_samples_leaf = leaf_size)\n",
    "    model.fit(train_X, train_Y)\n",
    "    score = r2_score(model.predict(test_X), test_Y)\n",
    "    if  score > max_score:\n",
    "        max_score = score\n",
    "        print('max score:' , max_score)\n",
    "        best_model = model\n",
    "        #score\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = best_model  #保存最佳的rf模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练lgb模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l1: 1621.28\tvalid_0's l2: 5.64774e+06\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l1: 1558.16\tvalid_0's l2: 5.22935e+06\n",
      "[3]\tvalid_0's l1: 1500.42\tvalid_0's l2: 4.85181e+06\n",
      "[4]\tvalid_0's l1: 1443.98\tvalid_0's l2: 4.50418e+06\n",
      "[5]\tvalid_0's l1: 1393.9\tvalid_0's l2: 4.19316e+06\n",
      "[6]\tvalid_0's l1: 1339.11\tvalid_0's l2: 3.88831e+06\n",
      "[7]\tvalid_0's l1: 1287.43\tvalid_0's l2: 3.60272e+06\n",
      "[8]\tvalid_0's l1: 1238.35\tvalid_0's l2: 3.34518e+06\n",
      "[9]\tvalid_0's l1: 1192.87\tvalid_0's l2: 3.11375e+06\n",
      "[10]\tvalid_0's l1: 1152.64\tvalid_0's l2: 2.91482e+06\n",
      "[11]\tvalid_0's l1: 1114.88\tvalid_0's l2: 2.72739e+06\n",
      "[12]\tvalid_0's l1: 1077.15\tvalid_0's l2: 2.54405e+06\n",
      "[13]\tvalid_0's l1: 1043\tvalid_0's l2: 2.38106e+06\n",
      "[14]\tvalid_0's l1: 1009.74\tvalid_0's l2: 2.2386e+06\n",
      "[15]\tvalid_0's l1: 979.876\tvalid_0's l2: 2.11532e+06\n",
      "[16]\tvalid_0's l1: 950.591\tvalid_0's l2: 1.98549e+06\n",
      "[17]\tvalid_0's l1: 923.949\tvalid_0's l2: 1.87762e+06\n",
      "[18]\tvalid_0's l1: 896.471\tvalid_0's l2: 1.76493e+06\n",
      "[19]\tvalid_0's l1: 870.433\tvalid_0's l2: 1.66296e+06\n",
      "[20]\tvalid_0's l1: 847.189\tvalid_0's l2: 1.58065e+06\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 847.189\tvalid_0's l2: 1.58065e+06\n",
      "Starting predicting...\n",
      "The rmse of prediction is: 0.7231832388029109\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(train_X, train_Y)\n",
    "lgb_eval = lgb.Dataset(test_X, test_Y, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "pred_Y = gbm.predict(test_X, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', r2_score(test_Y, pred_Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对模型进行融合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area', 'rentType', 'houseFloor', 'totalFloor', 'houseToward',\n",
       "       'houseDecoration', 'communityName', 'region', 'plate', 'buildYear',\n",
       "       'saleSecHouseNum', 'totalTradeMoney', 'totalTradeArea',\n",
       "       'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
       "       'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
       "       'supplyNewNum', 'supplyLandNum', 'supplyLandArea', 'tradeLandNum',\n",
       "       'tradeLandArea', 'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
       "       'newWorkers', 'residentPopulation', 'pv', 'uv', 'lookNum', 'month',\n",
       "       'year', 'Room', 'Hall', 'Bath', 'Room_Bath', 'trainsportNum',\n",
       "       'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          50\n",
       "1         129\n",
       "2         178\n",
       "3         312\n",
       "4        1256\n",
       "         ... \n",
       "40210    1208\n",
       "40211     852\n",
       "40212     851\n",
       "40213     790\n",
       "40214    3245\n",
       "Name: communityName, Length: 40215, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['communityName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate','communityName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>communityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rentType  houseFloor  houseToward  houseDecoration  region  plate  \\\n",
       "0         2           1            6                0       0     63   \n",
       "1         2           0            6                2       1     48   \n",
       "2         2           1            6                0       1     49   \n",
       "3         2           0            6                3       1     50   \n",
       "4         2           1            6                1       2     43   \n",
       "\n",
       "   communityName  \n",
       "0             50  \n",
       "1            129  \n",
       "2            178  \n",
       "3            312  \n",
       "4           1256  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[categorical_feats].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params={\n",
    "    'objective':'regression',\n",
    "    #'booster':'gbtree',\n",
    "    #'num_class':10, # 类别数，与 multisoftmax 并用\n",
    "    'gamma':0.1,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth':12, # 构建树的深度，越大越容易过拟合\n",
    "    'lambda':2,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample':0.7, # 随机采样训练样本\n",
    "    'colsample_bytree':0.7, # 生成树时进行的列采样\n",
    "    'min_child_weight':3, \n",
    "# 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "    'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.007, # 如同学习率\n",
    "    'seed':1000,\n",
    "    'nthread':7,# cpu 线程数\n",
    "    'eval_metric': 'l2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2_metric(preds, label):\n",
    "    return ('r2', r2_score(preds, label), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def model_ensemble(feature = train_X, label = train_Y, categorical_feats = categorical_feats, params = lgb_params,\n",
    "                  test = test_X):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "   \n",
    "    \"===================================第一轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 5000\n",
    "        clf = lgb.train(params, trn_data, num_round,valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "\n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    feature['pre'] = train_feat\n",
    "    test['pre'] = y_pred_final\n",
    "    \"===================================第二轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 5000\n",
    "        clf = lgb.train(params, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "    \n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    feature['pre_2'] = train_feat\n",
    "    test['pre_2'] = y_pred_final\n",
    "    \"=======================第三轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 5000\n",
    "        clf = lgb.train(params, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "    \n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    \n",
    "    return y_pred_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 605643\tvalid_1's l2: 730697\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttraining's l2: 604089\tvalid_1's l2: 730524\n",
      "fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 608310\tvalid_1's l2: 726770\n",
      "Early stopping, best iteration is:\n",
      "[575]\ttraining's l2: 586813\tvalid_1's l2: 725996\n",
      "fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 610466\tvalid_1's l2: 735016\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's l2: 568757\tvalid_1's l2: 730433\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's l2: 611294\tvalid_1's l2: 703962\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttraining's l2: 603030\tvalid_1's l2: 703729\n",
      "fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 588169\tvalid_1's l2: 826891\n",
      "Early stopping, best iteration is:\n",
      "[467]\ttraining's l2: 600001\tvalid_1's l2: 826156\n",
      "r2 score0.843251600045051\n",
      "r2:0.8594426650705866\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 613666\tvalid_1's l2: 753732\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttraining's l2: 611992\tvalid_1's l2: 753475\n",
      "fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 621301\tvalid_1's l2: 740135\n",
      "Early stopping, best iteration is:\n",
      "[504]\ttraining's l2: 620134\tvalid_1's l2: 739934\n",
      "fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 621978\tvalid_1's l2: 746482\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's l2: 604765\tvalid_1's l2: 744233\n",
      "fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 625516\tvalid_1's l2: 717732\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's l2: 609531\tvalid_1's l2: 716705\n",
      "fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 600992\tvalid_1's l2: 843645\n",
      "Early stopping, best iteration is:\n",
      "[471]\ttraining's l2: 611744\tvalid_1's l2: 843086\n",
      "r2 score0.8391725927275031\n",
      "r2:0.8550296114184635\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 616398\tvalid_1's l2: 760711\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's l2: 600339\tvalid_1's l2: 759546\n",
      "fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 623381\tvalid_1's l2: 742425\n",
      "Early stopping, best iteration is:\n",
      "[617]\ttraining's l2: 590238\tvalid_1's l2: 741701\n",
      "fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 622746\tvalid_1's l2: 749471\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's l2: 595472\tvalid_1's l2: 747401\n",
      "fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 628211\tvalid_1's l2: 719485\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's l2: 611743\tvalid_1's l2: 718420\n",
      "fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/gongbin/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 603195\tvalid_1's l2: 850652\n",
      "[1000]\ttraining's l2: 507505\tvalid_1's l2: 845126\n",
      "[1500]\ttraining's l2: 452503\tvalid_1's l2: 833973\n",
      "[2000]\ttraining's l2: 412896\tvalid_1's l2: 821673\n",
      "[2500]\ttraining's l2: 380918\tvalid_1's l2: 812009\n",
      "[3000]\ttraining's l2: 355098\tvalid_1's l2: 804203\n",
      "[3500]\ttraining's l2: 333014\tvalid_1's l2: 797672\n",
      "[4000]\ttraining's l2: 314035\tvalid_1's l2: 791509\n",
      "[4500]\ttraining's l2: 297455\tvalid_1's l2: 785641\n",
      "[5000]\ttraining's l2: 283009\tvalid_1's l2: 780737\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l2: 283009\tvalid_1's l2: 780737\n",
      "r2 score0.8669764564933371\n",
      "r2:0.8619147984769511\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
